{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AML Assignment 2\n",
    "\n",
    "## Supreet Singh - CS16BTECH11038\n",
    "\n",
    "(Done in Python 3)\n",
    "\n",
    "** NEED TO INSTALL MATPLOTLIB ** for Q6, part (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) \n",
    "\n",
    "Using Mercer's Condition, \n",
    "\n",
    "$  K(x,z) = K1(x,z) + K2(x,z) $ has to be positive semidefinite, i.e. Integral (dx.dz. f(x).K(x,z).f(z)) >= 0.\n",
    "\n",
    "Since this condition is true for K1 and K2, it is also true for K1+K2 (simply add those two to get the required inequality). Hence, this K is a valid kernal function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b)\n",
    "K(x,z) = K1(x,z) . K2(x,z)\n",
    "\n",
    "Let $ K1(x, z) = \\phi_1(x) . \\phi_1(z) $ \n",
    "\n",
    " $ K2(x, z) = \\phi_2(x) . \\phi_2(z) $ \n",
    " \n",
    "Then: (x, z are vectors)\n",
    "\n",
    "$$ K1 . K2 = (\\sum_i \\phi_1(x_i).\\phi_1(z_i)) . (\\sum_j \\phi_2(x_j).\\phi_2(z_j)) $$\n",
    "\n",
    "_note: Here $ \\phi_1(x_i) $ denotes i'th component of $ \\phi_1(x) $ _\n",
    "\n",
    "Which is equal to: \n",
    "\n",
    "$$ K1. K2 = \\sum_{i, j} \\phi_1(x_i).\\phi_2(x_j) . \\phi_1(z_i).\\phi_2(z_j) $$\n",
    "\n",
    "Set a new $$ \\phi_3(x_k) = \\phi_1(x_i).\\phi_2(x_j) $$ (similarly for z).\n",
    "\n",
    "We get, $$ K(x,z) = K1 . K2 = \\sum_k \\phi_3(x_k) . \\phi_3(z_k) = \\phi_3(x) . \\phi_3(z) $$\n",
    "\n",
    " **Hence, this K is decomposable into a dot product, and is a valid Kernel. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c)\n",
    "K(x,z) = h(K1(x,z))\n",
    "\n",
    "Using Mercer's Condition,\n",
    "\n",
    "$$ \\int dx.dz.f(x). K1(x,z) . f(z) \\ge 0 $$\n",
    "\n",
    "for any f(x) satisfying the criteria of Mercer's condition.\n",
    "\n",
    "$$ (\\forall a_i > 0 ): $$  \n",
    "\n",
    "$$ \\implies a_i \\int dx.dz.f(x). K1(x,z) . f(z) \\ge 0 $$\n",
    "\n",
    "\n",
    "\n",
    "$$ \\implies \\int dx.dz.f(x). a_i . K1(x,z) . f(z) \\ge 0 $$\n",
    "\n",
    "$$ \\implies \\int dx.dz.f(x). h(K1(x,z) . f(z) \\ge 0 $$\n",
    "\n",
    "where $$ h(K1) = a_0 + a_1 . K1 + a_2. K1^2 + ... $$ is a polynomial with positive coeffecients  $(a_i > 0 ) $ (Using (a) part for addition of kernel functions resulting in valid kernel function)\n",
    "\n",
    "Thus, ** This is a valid kernel ** because it satisfies mercer's condition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d)\n",
    "\n",
    "K(x,z) = $ e^ {K1(x,z)} $\n",
    "\n",
    "$ e^{K1(x,z)} $  can be approximated to a polynomial of K1(x,z) using Taylor Series:\n",
    "\n",
    "$ e^x = 1 + x + \\frac{x^2}{2!} + ... $\n",
    "\n",
    "In part(c), it has been shown that a polynomial function of a valid kernel is also a valid kernel. \n",
    "\n",
    "Thus, **this is also a valid kernel.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (e)\n",
    "K(x, z) = exp ($\\frac{-||x - z||^2}{\\sigma^2} $)\n",
    "\n",
    "It is known that K1(x,z) = exp ($\\frac{-||x - z||^2}{2.\\sigma^2} $) is a valid kernel (mentioned in slides).\n",
    "\n",
    "$ K(x,z) = (K1(x,z))^2$.\n",
    "\n",
    "Thus, using part (b), ** this is also a valid kernel. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data!\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "\n",
    "# Open the url for reading\n",
    "f1 = urllib.request.urlopen(\"http://www.amlbook.com/data/zip/features.train\")\n",
    "# fast reading function!\n",
    "rawTrainSet = np.loadtxt(f1)\n",
    "\n",
    "trainSet_X = []\n",
    "trainSet_y = []\n",
    "# Filter out only 1s/5s\n",
    "for x in rawTrainSet:\n",
    "    if x[0]==1.0 or x[0]==5.0 :\n",
    "        trainSet_X.append(x[1:])\n",
    "        trainSet_y.append(x[0])\n",
    "#print(trainSet_X)\n",
    "\n",
    "# loead test data\n",
    "f1 = urllib.request.urlopen(\"http://www.amlbook.com/data/zip/features.test\")\n",
    "rawTestSet = np.loadtxt(f1)\n",
    "testSet_X = []\n",
    "testSet_y = []\n",
    "for x in rawTestSet:\n",
    "    if x[0]==1.0 or x[0]==5.0 :\n",
    "        testSet_X.append(x[1:])\n",
    "        testSet_y.append(x[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a)\n",
    "Using linear kernel, and all of training data and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is :  97.87735849056604\n",
      "number of support vectors [Class +1, Class -1] is:  [14 14]\n"
     ]
    }
   ],
   "source": [
    "# training && accuracy reporting!\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mySvm = svm.SVC(kernel='linear')\n",
    "mySvm.fit(trainSet_X, trainSet_y)\n",
    "\n",
    "pred = mySvm.predict(testSet_X)\n",
    "print(\"Accuracy is : \", accuracy_score(testSet_y, pred)*100)\n",
    "print(\"number of support vectors [Class +1, Class -1] is: \", mySvm.n_support_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Using first 50 data points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is :  98.11320754716981 %\n",
      "number of support vectors [Class +1, Class -1] is:  [1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mySvm = svm.SVC(kernel='linear')\n",
    "mySvm.fit(trainSet_X[:50], trainSet_y[:50])\n",
    "\n",
    "pred = mySvm.predict(testSet_X)\n",
    "print(\"Accuracy is : \", accuracy_score(testSet_y, pred)*100, \"%\")\n",
    "print(\"number of support vectors [Class +1, Class -1] is: \", mySvm.n_support_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using first 100 data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is :  98.11320754716981 %\n",
      "number of support vectors [Class +1, Class -1] is:  [2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mySvm = svm.SVC(kernel='linear')\n",
    "mySvm.fit(trainSet_X[:100], trainSet_y[:100])\n",
    "\n",
    "pred = mySvm.predict(testSet_X)\n",
    "print(\"Accuracy is : \", accuracy_score(testSet_y, pred)*100, \"%\")\n",
    "print(\"number of support vectors [Class +1, Class -1] is: \", mySvm.n_support_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using first 200 data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is :  98.11320754716981 %\n",
      "number of support vectors [Class +1, Class -1] is:  [4 4]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mySvm = svm.SVC(kernel='linear')\n",
    "mySvm.fit(trainSet_X[:200], trainSet_y[:200])\n",
    "\n",
    "pred = mySvm.predict(testSet_X)\n",
    "print(\"Accuracy is : \", accuracy_score(testSet_y, pred)*100, \"%\")\n",
    "print(\"number of support vectors [Class +1, Class -1] is: \", mySvm.n_support_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using first 800 data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is :  98.11320754716981 %\n",
      "number of support vectors [Class +1, Class -1] is:  [7 7]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mySvm = svm.SVC(kernel='linear')\n",
    "mySvm.fit(trainSet_X[:800], trainSet_y[:800])\n",
    "\n",
    "pred = mySvm.predict(testSet_X)\n",
    "print(\"Accuracy is : \", accuracy_score(testSet_y, pred)*100, \"%\")\n",
    "print(\"number of support vectors [Class +1, Class -1] is: \", mySvm.n_support_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c) Comparing polynomial kernels with degree = 2 and 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=  0.0001\n",
      "Training Error for degree Q = 2  is :  1.8577834721332454 %\n",
      "Training Error for degree Q = 5  is :  0.5124919923126248 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "c = 0.0001\n",
    "\n",
    "mySvm_deg2 = svm.SVC(kernel='poly', degree=2, gamma='auto', C=c, coef0=1)\n",
    "mySvm_deg2.fit(trainSet_X, trainSet_y)\n",
    "\n",
    "mySvm_deg5 = svm.SVC(kernel='poly', degree=5,gamma='auto', C=c, coef0=1)\n",
    "mySvm_deg5.fit(trainSet_X, trainSet_y)\n",
    "\n",
    "pred2 = mySvm_deg2.predict(trainSet_X)\n",
    "pred5 = mySvm_deg5.predict(trainSet_X)\n",
    "\n",
    "print(\"C= \", c)\n",
    "print(\"Training Error for degree Q = 2  is : \", (1-accuracy_score(trainSet_y, pred2))*100, \"%\")\n",
    "print(\"Training Error for degree Q = 5  is : \", (1-accuracy_score(trainSet_y, pred5))*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) **False**. Training Error is **lower** for Q=5 compared to Q=2 for C = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=  0.001\n",
      "Support Vectors for degree Q = 2  is :  142\n",
      "Support Vectors for degree Q = 5  is :  26\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "c = 0.001\n",
    "\n",
    "mySvm_deg2 = svm.SVC(kernel='poly', degree=2, gamma='auto', C=c, coef0=1)\n",
    "mySvm_deg2.fit(trainSet_X, trainSet_y)\n",
    "\n",
    "mySvm_deg5 = svm.SVC(kernel='poly', degree=5,gamma='auto', C=c, coef0=1)\n",
    "mySvm_deg5.fit(trainSet_X, trainSet_y)\n",
    "\n",
    "print(\"C= \", c)\n",
    "print(\"Support Vectors for degree Q = 2  is : \", mySvm_deg2.n_support_.sum())\n",
    "print(\"Support Vectors for degree Q = 5  is : \", mySvm_deg5.n_support_.sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) **True** Number of support vectors is lower at Q = 5 for c = 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=  0.01\n",
      "Training Error for degree Q = 2  is :  0.4484304932735439 %\n",
      "Training Error for degree Q = 5  is :  0.384368994234463 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "c = 0.01\n",
    "\n",
    "mySvm_deg2 = svm.SVC(kernel='poly', degree=2, gamma='auto', C=c, coef0=1)\n",
    "mySvm_deg2.fit(trainSet_X, trainSet_y)\n",
    "\n",
    "mySvm_deg5 = svm.SVC(kernel='poly', degree=5,gamma='auto', C=c, coef0=1)\n",
    "mySvm_deg5.fit(trainSet_X, trainSet_y)\n",
    "\n",
    "pred2 = mySvm_deg2.predict(trainSet_X)\n",
    "pred5 = mySvm_deg5.predict(trainSet_X)\n",
    "\n",
    "print(\"C= \", c)\n",
    "print(\"Training Error for degree Q = 2  is : \", (1-accuracy_score(trainSet_y, pred2))*100, \"%\")\n",
    "print(\"Training Error for degree Q = 5  is : \", (1-accuracy_score(trainSet_y, pred5))*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) ** False ** Training error is lower in case of Q=5 and Q=2 for c = 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=  1\n",
      "Test error for degree Q=2 is :  1.8867924528301883 %\n",
      "Test error for degree Q=5 is :  1.8867924528301883 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "c = 1\n",
    "\n",
    "mySvm_deg2 = svm.SVC(kernel='poly', degree=2, gamma='auto', C=c, coef0=1)\n",
    "mySvm_deg2.fit(trainSet_X, trainSet_y)\n",
    "\n",
    "mySvm_deg5 = svm.SVC(kernel='poly', degree=5,gamma='auto', C=c, coef0=1)\n",
    "mySvm_deg5.fit(trainSet_X, trainSet_y)\n",
    "\n",
    "pred2 = mySvm_deg2.predict(testSet_X)\n",
    "pred5 = mySvm_deg5.predict(testSet_X)\n",
    "\n",
    "print(\"C= \", c)\n",
    "print(\"Test error for degree Q=2 is : \",(1-accuracy_score(testSet_y, pred2))*100, \"%\")\n",
    "print(\"Test error for degree Q=5 is : \", (1-accuracy_score(testSet_y, pred5))*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4). ** False ** Test error is same @ Q=5 and Q=2 for C = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C is:  0.01\n",
      "Test Error is :  2.1226415094339646 %\n",
      "Training Error is :  0.384368994234463 %\n",
      "---------------\n",
      "C is:  1\n",
      "Test Error is :  2.1226415094339646 %\n",
      "Training Error is :  0.4484304932735439 %\n",
      "---------------\n",
      "C is:  100\n",
      "Test Error is :  1.8867924528301883 %\n",
      "Training Error is :  0.32030749519538215 %\n",
      "---------------\n",
      "C is:  10000\n",
      "Test Error is :  1.8867924528301883 %\n",
      "Training Error is :  0.2562459961563124 %\n",
      "---------------\n",
      "C is:  1000000\n",
      "Test Error is :  2.1226415094339646 %\n",
      "Training Error is :  0.12812299807815064 %\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for i in [0.01, 1, 100, 10000, 1000000]:\n",
    "    mySvm = svm.SVC(kernel='rbf', C=i, gamma='auto')\n",
    "    mySvm.fit(trainSet_X, trainSet_y)\n",
    "    print(\"C is: \", i)\n",
    "    pred = mySvm.predict(testSet_X)\n",
    "    pred_train = mySvm.predict(trainSet_X)\n",
    "    print(\"Test Error is : \", (1-accuracy_score(testSet_y, pred))*100, \"%\")\n",
    "    print(\"Training Error is : \", (1-accuracy_score(trainSet_y, pred_train))*100, \"%\")\n",
    "    print(\"---------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lowest training error: ** C = 10^6 **\n",
    "\n",
    "Lowest test error: ** C = 100 or 10^4 ** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q(5)\n",
    "\n",
    "## (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n"
     ]
    }
   ],
   "source": [
    "# Loading Data!\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "\n",
    "# Open the url for reading\n",
    "f1 = open(\"gisette_train.labels\", \"r\")\n",
    "# fast reading function!\n",
    "_5_trainSet_y = np.loadtxt(f1)\n",
    "\n",
    "print(len(trainSet_y))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = open(\"gisette_valid.labels\", \"r\")\n",
    "_5_validSet_y = np.loadtxt(f1)\n",
    "\n",
    "#print(_5_validSet_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = open(\"gisette_valid.data\", \"r\")\n",
    "_5_validSet_X = np.loadtxt(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n"
     ]
    }
   ],
   "source": [
    "f1 = open(\"gisette_train.data\", \"r\")\n",
    "_5_trainSet_X = np.loadtxt(f1)\n",
    "print(len(_5_trainSet_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mySvm_5 = svm.SVC(kernel='linear')\n",
    "mySvm_5.fit(_5_trainSet_X, _5_trainSet_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error is :  2.400000000000002 %\n",
      "Training Error is :  0.0 %\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "pred = mySvm_5.predict(_5_validSet_X)\n",
    "pred_train = mySvm_5.predict(_5_trainSet_X)\n",
    "print(\"Test Error is : \", (1-accuracy_score(_5_validSet_y, pred))*100, \"%\")\n",
    "print(\"Training Error is : \", (1-accuracy_score(_5_trainSet_y, pred_train))*100, \"%\")\n",
    "print(\"---------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of support vectors:  1084\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of support vectors: \", mySvm_5.n_support_.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF Kernel!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"RBF Kernel!\")\n",
    "\n",
    "mySvm_5R = svm.SVC(kernel='rbf', gamma=0.001)\n",
    "mySvm_5R.fit(_5_trainSet_X, _5_trainSet_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error is :  50.0 %\n",
      "Training Error is :  0.0 %\n",
      "Number of support vectors:  6000\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "pred = mySvm_5R.predict(_5_validSet_X)\n",
    "pred_train = mySvm_5R.predict(_5_trainSet_X)\n",
    "print(\"Test Error is : \", (1-accuracy_score(_5_validSet_y, pred))*100, \"%\")\n",
    "print(\"Training Error is : \", (1-accuracy_score(_5_trainSet_y, pred_train))*100, \"%\")\n",
    "print(\"Number of support vectors: \", mySvm_5R.n_support_.sum())\n",
    "print(\"---------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poly Kernel!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/supreet/.local/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=1,\n",
       "  decision_function_shape='ovr', degree=2, gamma='auto_deprecated',\n",
       "  kernel='poly', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Poly Kernel!\")\n",
    "\n",
    "mySvm_5P = svm.SVC(kernel='poly', degree=2, coef0=1)\n",
    "mySvm_5P.fit(_5_trainSet_X, _5_trainSet_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error is :  2.100000000000002 %\n",
      "Training Error is :  0.0 %\n",
      "Number of support vectors:  1755\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "pred = mySvm_5P.predict(_5_validSet_X)\n",
    "pred_train = mySvm_5P.predict(_5_trainSet_X)\n",
    "print(\"Test Error is : \", (1-accuracy_score(_5_validSet_y, pred))*100, \"%\")\n",
    "print(\"Training Error is : \", (1-accuracy_score(_5_trainSet_y, pred_train))*100, \"%\")\n",
    "print(\"Number of support vectors: \", mySvm_5P.n_support_.sum())\n",
    "print(\"---------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Both yield equal training error of 0%. However, on test data, rbf kernel performs very poorly ~50% accuracy, whereas polynomial kernel gives high ~98% accuracy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a)\n",
    "\n",
    "Here:\n",
    "\n",
    "* I have used the random subset of data to be chosen for training each tree to be 4/5th of total training set.\n",
    "\n",
    "* k = number of trees = 10\n",
    "\n",
    "* To prevent infinite recursion (there is some probability that the random attributes are such that they do not result in a split, but still contain objects of different classes), recursion has been stopped in such cases.\n",
    "\n",
    "* Decision tree class from previous assignment has been modified slightly to suit my needs\n",
    "\n",
    "* A new **class** for random forests, **MyRF()** has been created. Its parameters are self explanatory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data !\n",
    "import numpy as np\n",
    "f = open(\"spam.data\", \"r\")\n",
    "rawSet_6 = np.loadtxt(f)\n",
    "\n",
    "np.random.shuffle(rawSet_6)\n",
    "#print(rawSet_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30 % data is test data!\n",
    "test_set_6 = [x for i, x in enumerate(rawSet_6) if i % 10 == 9 or i % 10 == 6 or i%7 == 3]\n",
    "train_set_6 =  [x for i, x in enumerate(rawSet_6) if i % 10 != 9 and i % 10 != 6 and i%7 != 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not used as such, but should do it so that python list-comprehends train_set_6 and \n",
    "# does not cause recursion error\n",
    "train_set_6_X = [x[:-1] for x in (train_set_6) ]\n",
    "train_set_6_y = [x[-1] for x in (train_set_6)]\n",
    "\n",
    "test_set_6_X = [x[:-1] for x in (test_set_6) ]\n",
    "test_set_6_y = [x[-1] for x in (test_set_6)]\n",
    "#print(train_set_6_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# Total number of attribs\n",
    "M = 58\n",
    "# Number of features for split! , Last is class label.\n",
    "m2 = (math.sqrt(M-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0,
     10,
     112,
     117
    ]
   },
   "outputs": [],
   "source": [
    "# Decision Tree code.\n",
    "#print(train_set_6)\n",
    "#print(test_set_6)\n",
    "## Code for decision Tree!\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "# Enter You Name Here\n",
    "myname = \"Supreet\" # or \"Doe-Jane-\"\n",
    "\n",
    "class Node():\n",
    "    left = None\n",
    "    right = None\n",
    "    ans = 2 # 2 means none, 0,1 -> the classification\n",
    "    attrib = 0 #index of attribute to split on\n",
    "    val = 0 #the value to split on. \n",
    "    def __init__(self, a, v, q):\n",
    "        self.attrib = a\n",
    "        self.val = v\n",
    "        self.ans = q\n",
    "        \n",
    "    def isLeaf(self): #boolean\n",
    "        if self.ans == 2:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "\n",
    "# Implement your decision tree below\n",
    "class DecisionTree():\n",
    "    tree = Node(0, 0, 2)\n",
    "    max_depth = 2900\n",
    "    depth = 0\n",
    "    \n",
    "    m_feat = -1 #Need to be set manually to >0\n",
    "    \n",
    "    def splitVal(self, data, idx): # retuurns mean\n",
    "        sum = 0.0\n",
    "        for x in data:\n",
    "            sum = sum+ float(x[idx])\n",
    "        \n",
    "        return float(float(sum)/float(len(data)))\n",
    "        \n",
    "    def entropy(self, pa, na, ntot): #returns float.\n",
    "        if pa == 1 or pa == 0:\n",
    "            return 0\n",
    "        #print(pa)\n",
    "        \n",
    "        e = float(pa) * float(math.log(pa, 2))\n",
    "        e = e + float((1-pa) * math.log(1-pa, 2))\n",
    "        \n",
    "        return float(-1)*(float(na)/float(ntot))*e\n",
    "        \n",
    "    \n",
    "    def prob1(self, data): #Probability of items to be in class 1.\n",
    "        if len(data) == 0:\n",
    "            return float(0)\n",
    "        \n",
    "        sum = 0\n",
    "        for x in data:\n",
    "            sum = sum + int(x[M-1]) # 11th index (12th elem) is the quality\n",
    "        #print(\"sum: \", sum, \"len: \", len(data))\n",
    "        g= float(float(sum)/float(len(data)))\n",
    "        #print(\"prob:\", g)\n",
    "        return g\n",
    "    \n",
    "    def learn(self, training_set): #returns a node with the split conditions.\n",
    "        # implement this function\n",
    "         \n",
    "        if len(training_set) == 0:\n",
    "            return None\n",
    "        \n",
    "        tpl = self.splitNode(training_set)\n",
    "        root = Node(tpl[1], tpl[2], 2)\n",
    "        \n",
    "        #print(\"got tuple to split: @ attrib: %d, value: %f\" % (root.attrib, root.val) )\n",
    "        \n",
    "        if self.prob1(training_set) == 1 :\n",
    "            root.ans = 1\n",
    "            return root\n",
    "        \n",
    "        elif self.prob1(training_set) == 0:\n",
    "            root.ans = 0\n",
    "            return root\n",
    "        \n",
    "        else :\n",
    "            self.depth = self.depth + 1\n",
    "            #print(self.depth)\n",
    "            l1 = [x for x in training_set if float(x[root.attrib]) <= root.val]\n",
    "            l2 = [x for x in training_set if float(x[root.attrib]) > root.val]\n",
    "            \n",
    "            #print(\"left: %d, right %d\" %(len(l1), len(l2)))\n",
    "            if np.array_equal(training_set, l1):\n",
    "                root.ans = 1 if self.prob1(l1) > 0.5 else 0\n",
    "                return root\n",
    "            elif np.array_equal(training_set, l2):\n",
    "                root.ans = 1 if self.prob1(l2) > 0.5 else 0\n",
    "                return root\n",
    "            \n",
    "            root.left = self.learn(l1)\n",
    "            root.right = self.learn(l2)\n",
    "            return root\n",
    "        '''else:\n",
    "            if self.prob1(training_set)>0.5:\n",
    "                root.ans = 1\n",
    "                return root\n",
    "            else:\n",
    "                root.ans = 0\n",
    "                return root\n",
    "        '''\n",
    "\n",
    "    # implement this function\n",
    "    def classify(self, test_instance):\n",
    "        #result = 0 # baseline: always classifies as 0\n",
    "        result = self.treeTraverse(test_instance, self.tree)\n",
    "        return result\n",
    "    \n",
    "    def treeTraverse(self, x_vector, node: Node) -> int:\n",
    "        if node is None:\n",
    "            return -1\n",
    "        elif not node.isLeaf():\n",
    "            return node.ans\n",
    "        elif float(x_vector[node.attrib]) <= node.val:\n",
    "            return self.treeTraverse(x_vector, node.left)\n",
    "        else:\n",
    "            return self.treeTraverse(x_vector, node.right)\n",
    "            \n",
    "        \n",
    "    \n",
    "    def splitNode(self, data): # returns the minimum entropy.\n",
    "        me = float(11000)\n",
    "        index = 0\n",
    "        Nm = len(data)\n",
    "        mSVal = 0.0\n",
    "        \n",
    "        # Choose a random list of features to check split on!\n",
    "        split_features = []\n",
    "        #print(self.m_feat)\n",
    "        \n",
    "        split_features = np.random.choice(np.arange(M-1), int(self.m_feat), replace=False)\n",
    "        #print(split_features)\n",
    "        for i in split_features: # 11 is the number of attributes \n",
    "            sv = self.splitVal(data, i)\n",
    "            l1 = [x for x in data if float(x[i]) <= sv]\n",
    "            l2 = [x for x in data if float(x[i]) > sv]\n",
    "            pa1 = self.prob1(l1)\n",
    "            pa2 = self.prob1(l2)\n",
    "            #print(\"## \", pa1, pa2)\n",
    "            eThis = self.entropy(pa1, len(l1), Nm) + self.entropy(pa2, len(l2), Nm)\n",
    "            #print(\"Entropy got: %f, me was: \" % eThis, me)\n",
    "            #print(eThis < me)\n",
    "                \n",
    "            if eThis < me:\n",
    "                me = eThis\n",
    "                index = i\n",
    "                mSVal = sv\n",
    "            '''\n",
    "            me = eThis if eThis < me else me\n",
    "            index = i if eThis < me else index\n",
    "            print(\"inedx now is: %d\" % index)\n",
    "            mSVal = sv if eThis < me else mSVal\n",
    "            '''\n",
    "            #min = eThis < min ? eThis : min\n",
    "        return (me, index, mSVal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class MyRF():\n",
    "    #k = 10 # Number of trees.\n",
    "    #subSize = 20 # Size of subset of training points!\n",
    "    #trees = []\n",
    "    #m \n",
    "    def __init__(self, k, subSize, features_to_split):\n",
    "        self.k = k\n",
    "        self.subSize = int(subSize)\n",
    "        self.m = int(features_to_split)\n",
    "        self.trees=[]\n",
    "        self.oobError = 0.0\n",
    "    \n",
    "    def learnForest(self, data):\n",
    "        for i in range(self.k):\n",
    "            tree = DecisionTree()\n",
    "            tree.m_feat = int(self.m)\n",
    "            #tree.tree = tree.learn(random.choices(data, k=self.subSize))\n",
    "            np.random.shuffle(data)\n",
    "            tree.tree = tree.learn(data[:self.subSize])\n",
    "            \n",
    "            results = []\n",
    "            for instance in data[self.subSize:]:\n",
    "                result = tree.classify( instance[:-1] )\n",
    "                results.append( (result) == int(instance[-1]))\n",
    "            self.oobError += float(results.count(False)/float(len(results)))\n",
    "            self.trees.append(tree)\n",
    "    \n",
    "    def classify(self, dataPoint): # data point is without the class label!\n",
    "        n1 = 0\n",
    "        \n",
    "        for i in range(self.k):\n",
    "            result = self.trees[i].classify(dataPoint)\n",
    "            n1 = n1 + result\n",
    "        \n",
    "        if n1 >= int(self.k/2): # Majority Voting!!\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def getOOBError(self):\n",
    "        return float(self.oobError/self.k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = MyRF(10, subSize=len(train_set_6)/1.25, features_to_split=int(m2))\n",
    "rf.learnForest(train_set_6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9468\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for instance in test_set_6:\n",
    "    result = rf.classify( instance[:-1] )\n",
    "    results.append( (result) == int(instance[-1]))\n",
    "    \n",
    "accuracy = float(results.count(True))/float(len(results))\n",
    "print (\"accuracy: %.4f\" % accuracy) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing with sklearn's random forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9426399447131997\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "clf.fit(train_set_6_X, train_set_6_y)\n",
    "\n",
    "pred = clf.predict(test_set_6_X)\n",
    "\n",
    "print(\"accuracy: \", accuracy_score(test_set_6_y, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My implementation gave slighly **higher** (ON AVERAGE) accuracy compared to sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b)\n",
    "\n",
    "Sensitivity to 'm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For m =  1.8874586088176875 -> Accuracy = 0.8970\n",
      "OOB Error =  0.17559429477020602\n",
      "-------------------------\n",
      "For m =  2.516611478423583 -> Accuracy = 0.9316\n",
      "OOB Error =  0.1386687797147385\n",
      "-------------------------\n",
      "For m =  3.774917217635375 -> Accuracy = 0.9323\n",
      "OOB Error =  0.11014263074484945\n",
      "-------------------------\n",
      "For m =  7.54983443527075 -> Accuracy = 0.9523\n",
      "OOB Error =  0.09286846275752773\n",
      "-------------------------\n",
      "For m =  15.0996688705415 -> Accuracy = 0.9489\n",
      "OOB Error =  0.10015847860538826\n",
      "-------------------------\n",
      "For m =  22.64950330581225 -> Accuracy = 0.9371\n",
      "OOB Error =  0.0873217115689382\n",
      "-------------------------\n",
      "For m =  30.199337741083 -> Accuracy = 0.9468\n",
      "OOB Error =  0.08526148969889066\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "m_vals = [m2/4,m2/3, m2/2, m2, 2*m2, 3*m2, 4*m2]\n",
    "\n",
    "acc_s = []\n",
    "oobE = []\n",
    "\n",
    "for md in m_vals:\n",
    "    rf =  MyRF(10, subSize=len(train_set_6)/1.25, features_to_split=int(md))\n",
    "    rf.learnForest(train_set_6)\n",
    "    results2 = []\n",
    "    acc = []\n",
    "    i=0\n",
    "    for instance2 in test_set_6:\n",
    "        result = rf.classify( instance2[:-1] )\n",
    "        #print(\"ithpoint: \", i, \"as: \", result)\n",
    "        #i+=1\n",
    "        results2.append( (result) == int(instance2[-1]))\n",
    "    #print((results.count(True)))\n",
    "    \n",
    "    accuracy2 = float(results2.count(True))/float(len(results2))\n",
    "    acc_s.append(accuracy2)\n",
    "    oobE.append(rf.getOOBError())\n",
    "    print (\"For m = \", md,\"-> Accuracy = %.4f\" % accuracy2)\n",
    "    print(\"OOB Error = \", rf.getOOBError())\n",
    "    print(\"-------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, ** m2 ** = sqrt(Number of Attributes)\n",
    " \n",
    "Value of m has been chosen from this range: [m2/4,m2/3, m2/2, m2, 2 x m2, 3 x m2, 4 x m2]\n",
    "\n",
    "**Observations**\n",
    "\n",
    "For lower values of 'm', the classifier is very sensitive to changes in the value of m, with accuracy changing dramatically for small changes in m. However, at larger values ~ $ 2 * m2 $, this sensitivity reduces and accuracy changes only slightly for changes in m."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(m_vals, oobE)\n",
    "plt.xlabel(\"m: Number of features\")\n",
    "plt.ylabel(\"OOB Error\")\n",
    "plt.title(\"m vs OOB Error\")\n",
    "plt.show()\n",
    "\n",
    "print(\"---------------------------------\")\n",
    "\n",
    "plt.plot(m_vals, [1-x for x in acc_s])\n",
    "plt.xlabel(\"m: Number of features\")\n",
    "plt.ylabel(\"Test Error\")\n",
    "plt.title(\"m vs Testing Error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
