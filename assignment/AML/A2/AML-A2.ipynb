{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AML Assignment 2\n",
    "\n",
    "## Supreet Singh - CS16BTECH11038\n",
    "\n",
    "(Done in Python 3)\n",
    "\n",
    "** NEED TO INSTALL MATPLOTLIB ** for Q6, part (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) \n",
    "\n",
    "Using Mercer's Condition, \n",
    "\n",
    "$  K(x,z) = K1(x,z) + K2(x,z) $ has to be positive semidefinite, i.e. Integral (dx.dz. f(x).K(x,z).f(z)) >= 0.\n",
    "\n",
    "Since this condition is true for K1 and K2, it is also true for K1+K2 (simply add those two to get the required inequality). Hence, this K is a valid kernal function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b)\n",
    "K(x,z) = K1(x,z) . K2(x,z)\n",
    "\n",
    "Let $ K1(x, z) = \\phi_1(x) . \\phi_1(z) $ \n",
    "\n",
    " $ K2(x, z) = \\phi_2(x) . \\phi_2(z) $ \n",
    " \n",
    "Then: (x, z are vectors)\n",
    "\n",
    "$$ K1 . K2 = (\\sum_i \\phi_1(x_i).\\phi_1(z_i)) . (\\sum_j \\phi_2(x_j).\\phi_2(z_j)) $$\n",
    "\n",
    "_note: Here $ \\phi_1(x_i) $ denotes i'th component of $ \\phi_1(x) $ _\n",
    "\n",
    "Which is equal to: \n",
    "\n",
    "$$ K1. K2 = \\sum_{i, j} \\phi_1(x_i).\\phi_2(x_j) . \\phi_1(z_i).\\phi_2(z_j) $$\n",
    "\n",
    "Set a new $$ \\phi_3(x_k) = \\phi_1(x_i).\\phi_2(x_j) $$ (similarly for z).\n",
    "\n",
    "We get, $$ K(x,z) = K1 . K2 = \\sum_k \\phi_3(x_k) . \\phi_3(z_k) = \\phi_3(x) . \\phi_3(z) $$\n",
    "\n",
    " **Hence, this K is decomposable into a dot product, and is a valid Kernel. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c)\n",
    "K(x,z) = h(K1(x,z))\n",
    "\n",
    "Using Mercer's Condition,\n",
    "\n",
    "$$ \\int dx.dz.f(x). K1(x,z) . f(z) \\ge 0 $$\n",
    "\n",
    "for any f(x) satisfying the criteria of Mercer's condition.\n",
    "\n",
    "$$ (\\forall a_i > 0 ): $$  \n",
    "\n",
    "$$ \\implies a_i \\int dx.dz.f(x). K1(x,z) . f(z) \\ge 0 $$\n",
    "\n",
    "\n",
    "\n",
    "$$ \\implies \\int dx.dz.f(x). a_i . K1(x,z) . f(z) \\ge 0 $$\n",
    "\n",
    "$$ \\implies \\int dx.dz.f(x). h(K1(x,z) . f(z) \\ge 0 $$\n",
    "\n",
    "where $$ h(K1) = a_0 + a_1 . K1 + a_2. K1^2 + ... $$ is a polynomial with positive coeffecients  $(a_i > 0 ) $ (Using (a) part for addition of kernel functions resulting in valid kernel function)\n",
    "\n",
    "Thus, ** This is a valid kernel ** because it satisfies mercer's condition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d)\n",
    "\n",
    "K(x,z) = $ e^ {K1(x,z)} $\n",
    "\n",
    "$ e^{K1(x,z)} $  can be approximated to a polynomial of K1(x,z) using Taylor Series:\n",
    "\n",
    "$ e^x = 1 + x + \\frac{x^2}{2!} + ... $\n",
    "\n",
    "In part(c), it has been shown that a polynomial function of a valid kernel is also a valid kernel. \n",
    "\n",
    "Thus, **this is also a valid kernel.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (e)\n",
    "K(x, z) = exp ($\\frac{-||x - z||^2}{\\sigma^2} $)\n",
    "\n",
    "It is known that K1(x,z) = exp ($\\frac{-||x - z||^2}{2.\\sigma^2} $) is a valid kernel (mentioned in slides).\n",
    "\n",
    "$ K(x,z) = (K1(x,z))^2$.\n",
    "\n",
    "Thus, using part (b), ** this is also a valid kernel. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data!\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "\n",
    "# Open the url for reading\n",
    "f1 = urllib.request.urlopen(\"http://www.amlbook.com/data/zip/features.train\")\n",
    "# fast reading function!\n",
    "rawTrainSet = np.loadtxt(f1)\n",
    "\n",
    "trainSet_X = []\n",
    "trainSet_y = []\n",
    "# Filter out only 1s/5s\n",
    "for x in rawTrainSet:\n",
    "    if x[0]==1.0 or x[0]==5.0 :\n",
    "        trainSet_X.append(x[1:])\n",
    "        trainSet_y.append(x[0])\n",
    "#print(trainSet_X)\n",
    "\n",
    "# loead test data\n",
    "f1 = urllib.request.urlopen(\"http://www.amlbook.com/data/zip/features.test\")\n",
    "rawTestSet = np.loadtxt(f1)\n",
    "testSet_X = []\n",
    "testSet_y = []\n",
    "for x in rawTestSet:\n",
    "    if x[0]==1.0 or x[0]==5.0 :\n",
    "        testSet_X.append(x[1:])\n",
    "        testSet_y.append(x[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a)\n",
    "Using linear kernel, and all of training data and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is :  97.87735849056604\n",
      "number of support vectors [Class +1, Class -1] is:  [14 14]\n"
     ]
    }
   ],
   "source": [
    "# training && accuracy reporting!\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mySvm = svm.SVC(kernel='linear')\n",
    "mySvm.fit(trainSet_X, trainSet_y)\n",
    "\n",
    "pred = mySvm.predict(testSet_X)\n",
    "print(\"Accuracy is : \", accuracy_score(testSet_y, pred)*100)\n",
    "print(\"number of support vectors [Class +1, Class -1] is: \", mySvm.n_support_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Using first 50 data points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is :  98.11320754716981 %\n",
      "number of support vectors [Class +1, Class -1] is:  [1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mySvm = svm.SVC(kernel='linear')\n",
    "mySvm.fit(trainSet_X[:50], trainSet_y[:50])\n",
    "\n",
    "pred = mySvm.predict(testSet_X)\n",
    "print(\"Accuracy is : \", accuracy_score(testSet_y, pred)*100, \"%\")\n",
    "print(\"number of support vectors [Class +1, Class -1] is: \", mySvm.n_support_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using first 100 data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is :  98.11320754716981 %\n",
      "number of support vectors [Class +1, Class -1] is:  [2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mySvm = svm.SVC(kernel='linear')\n",
    "mySvm.fit(trainSet_X[:100], trainSet_y[:100])\n",
    "\n",
    "pred = mySvm.predict(testSet_X)\n",
    "print(\"Accuracy is : \", accuracy_score(testSet_y, pred)*100, \"%\")\n",
    "print(\"number of support vectors [Class +1, Class -1] is: \", mySvm.n_support_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using first 200 data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is :  98.11320754716981 %\n",
      "number of support vectors [Class +1, Class -1] is:  [4 4]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mySvm = svm.SVC(kernel='linear')\n",
    "mySvm.fit(trainSet_X[:200], trainSet_y[:200])\n",
    "\n",
    "pred = mySvm.predict(testSet_X)\n",
    "print(\"Accuracy is : \", accuracy_score(testSet_y, pred)*100, \"%\")\n",
    "print(\"number of support vectors [Class +1, Class -1] is: \", mySvm.n_support_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using first 800 data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is :  98.11320754716981 %\n",
      "number of support vectors [Class +1, Class -1] is:  [7 7]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mySvm = svm.SVC(kernel='linear')\n",
    "mySvm.fit(trainSet_X[:800], trainSet_y[:800])\n",
    "\n",
    "pred = mySvm.predict(testSet_X)\n",
    "print(\"Accuracy is : \", accuracy_score(testSet_y, pred)*100, \"%\")\n",
    "print(\"number of support vectors [Class +1, Class -1] is: \", mySvm.n_support_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c) Comparing polynomial kernels with degree = 2 and 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=  0.0001\n",
      "Training Error for degree Q = 2  is :  1.8577834721332454 %\n",
      "Training Error for degree Q = 5  is :  0.5124919923126248 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "c = 0.0001\n",
    "\n",
    "mySvm_deg2 = svm.SVC(kernel='poly', degree=2, gamma='auto', C=c, coef0=1)\n",
    "mySvm_deg2.fit(trainSet_X, trainSet_y)\n",
    "\n",
    "mySvm_deg5 = svm.SVC(kernel='poly', degree=5,gamma='auto', C=c, coef0=1)\n",
    "mySvm_deg5.fit(trainSet_X, trainSet_y)\n",
    "\n",
    "pred2 = mySvm_deg2.predict(trainSet_X)\n",
    "pred5 = mySvm_deg5.predict(trainSet_X)\n",
    "\n",
    "print(\"C= \", c)\n",
    "print(\"Training Error for degree Q = 2  is : \", (1-accuracy_score(trainSet_y, pred2))*100, \"%\")\n",
    "print(\"Training Error for degree Q = 5  is : \", (1-accuracy_score(trainSet_y, pred5))*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) **False**. Training Error is **lower** for Q=5 compared to Q=2 for C = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=  0.001\n",
      "Support Vectors for degree Q = 2  is :  142\n",
      "Support Vectors for degree Q = 5  is :  26\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "c = 0.001\n",
    "\n",
    "mySvm_deg2 = svm.SVC(kernel='poly', degree=2, gamma='auto', C=c, coef0=1)\n",
    "mySvm_deg2.fit(trainSet_X, trainSet_y)\n",
    "\n",
    "mySvm_deg5 = svm.SVC(kernel='poly', degree=5,gamma='auto', C=c, coef0=1)\n",
    "mySvm_deg5.fit(trainSet_X, trainSet_y)\n",
    "\n",
    "print(\"C= \", c)\n",
    "print(\"Support Vectors for degree Q = 2  is : \", mySvm_deg2.n_support_.sum())\n",
    "print(\"Support Vectors for degree Q = 5  is : \", mySvm_deg5.n_support_.sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) **True** Number of support vectors is lower at Q = 5 for c = 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=  0.01\n",
      "Training Error for degree Q = 2  is :  0.4484304932735439 %\n",
      "Training Error for degree Q = 5  is :  0.384368994234463 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "c = 0.01\n",
    "\n",
    "mySvm_deg2 = svm.SVC(kernel='poly', degree=2, gamma='auto', C=c, coef0=1)\n",
    "mySvm_deg2.fit(trainSet_X, trainSet_y)\n",
    "\n",
    "mySvm_deg5 = svm.SVC(kernel='poly', degree=5,gamma='auto', C=c, coef0=1)\n",
    "mySvm_deg5.fit(trainSet_X, trainSet_y)\n",
    "\n",
    "pred2 = mySvm_deg2.predict(trainSet_X)\n",
    "pred5 = mySvm_deg5.predict(trainSet_X)\n",
    "\n",
    "print(\"C= \", c)\n",
    "print(\"Training Error for degree Q = 2  is : \", (1-accuracy_score(trainSet_y, pred2))*100, \"%\")\n",
    "print(\"Training Error for degree Q = 5  is : \", (1-accuracy_score(trainSet_y, pred5))*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) ** False ** Training error is lower in case of Q=5 and Q=2 for c = 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=  1\n",
      "Test error for degree Q=2 is :  1.8867924528301883 %\n",
      "Test error for degree Q=5 is :  1.8867924528301883 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "c = 1\n",
    "\n",
    "mySvm_deg2 = svm.SVC(kernel='poly', degree=2, gamma='auto', C=c, coef0=1)\n",
    "mySvm_deg2.fit(trainSet_X, trainSet_y)\n",
    "\n",
    "mySvm_deg5 = svm.SVC(kernel='poly', degree=5,gamma='auto', C=c, coef0=1)\n",
    "mySvm_deg5.fit(trainSet_X, trainSet_y)\n",
    "\n",
    "pred2 = mySvm_deg2.predict(testSet_X)\n",
    "pred5 = mySvm_deg5.predict(testSet_X)\n",
    "\n",
    "print(\"C= \", c)\n",
    "print(\"Test error for degree Q=2 is : \",(1-accuracy_score(testSet_y, pred2))*100, \"%\")\n",
    "print(\"Test error for degree Q=5 is : \", (1-accuracy_score(testSet_y, pred5))*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4). ** False ** Test error is same @ Q=5 and Q=2 for C = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C is:  0.01\n",
      "Test Error is :  2.1226415094339646 %\n",
      "Training Error is :  0.384368994234463 %\n",
      "---------------\n",
      "C is:  1\n",
      "Test Error is :  2.1226415094339646 %\n",
      "Training Error is :  0.4484304932735439 %\n",
      "---------------\n",
      "C is:  100\n",
      "Test Error is :  1.8867924528301883 %\n",
      "Training Error is :  0.32030749519538215 %\n",
      "---------------\n",
      "C is:  10000\n",
      "Test Error is :  1.8867924528301883 %\n",
      "Training Error is :  0.2562459961563124 %\n",
      "---------------\n",
      "C is:  1000000\n",
      "Test Error is :  2.1226415094339646 %\n",
      "Training Error is :  0.12812299807815064 %\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for i in [0.01, 1, 100, 10000, 1000000]:\n",
    "    mySvm = svm.SVC(kernel='rbf', C=i, gamma='auto')\n",
    "    mySvm.fit(trainSet_X, trainSet_y)\n",
    "    print(\"C is: \", i)\n",
    "    pred = mySvm.predict(testSet_X)\n",
    "    pred_train = mySvm.predict(trainSet_X)\n",
    "    print(\"Test Error is : \", (1-accuracy_score(testSet_y, pred))*100, \"%\")\n",
    "    print(\"Training Error is : \", (1-accuracy_score(trainSet_y, pred_train))*100, \"%\")\n",
    "    print(\"---------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lowest training error: ** C = 10^6 **\n",
    "\n",
    "Lowest test error: ** C = 100 or 10^4 ** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q(5)\n",
    "\n",
    "## (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n"
     ]
    }
   ],
   "source": [
    "# Loading Data!\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "\n",
    "# Open the url for reading\n",
    "f1 = open(\"gisette_train.labels\", \"r\")\n",
    "# fast reading function!\n",
    "_5_trainSet_y = np.loadtxt(f1)\n",
    "\n",
    "print(len(trainSet_y))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = open(\"gisette_valid.labels\", \"r\")\n",
    "_5_validSet_y = np.loadtxt(f1)\n",
    "\n",
    "#print(_5_validSet_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = open(\"gisette_valid.data\", \"r\")\n",
    "_5_validSet_X = np.loadtxt(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n"
     ]
    }
   ],
   "source": [
    "f1 = open(\"gisette_train.data\", \"r\")\n",
    "_5_trainSet_X = np.loadtxt(f1)\n",
    "print(len(_5_trainSet_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mySvm_5 = svm.SVC(kernel='linear')\n",
    "mySvm_5.fit(_5_trainSet_X, _5_trainSet_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error is :  2.400000000000002 %\n",
      "Training Error is :  0.0 %\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "pred = mySvm_5.predict(_5_validSet_X)\n",
    "pred_train = mySvm_5.predict(_5_trainSet_X)\n",
    "print(\"Test Error is : \", (1-accuracy_score(_5_validSet_y, pred))*100, \"%\")\n",
    "print(\"Training Error is : \", (1-accuracy_score(_5_trainSet_y, pred_train))*100, \"%\")\n",
    "print(\"---------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of support vectors:  1084\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of support vectors: \", mySvm_5.n_support_.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF Kernel!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"RBF Kernel!\")\n",
    "\n",
    "mySvm_5R = svm.SVC(kernel='rbf', gamma=0.001)\n",
    "mySvm_5R.fit(_5_trainSet_X, _5_trainSet_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error is :  50.0 %\n",
      "Training Error is :  0.0 %\n",
      "Number of support vectors:  6000\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "pred = mySvm_5R.predict(_5_validSet_X)\n",
    "pred_train = mySvm_5R.predict(_5_trainSet_X)\n",
    "print(\"Test Error is : \", (1-accuracy_score(_5_validSet_y, pred))*100, \"%\")\n",
    "print(\"Training Error is : \", (1-accuracy_score(_5_trainSet_y, pred_train))*100, \"%\")\n",
    "print(\"Number of support vectors: \", mySvm_5R.n_support_.sum())\n",
    "print(\"---------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poly Kernel!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/supreet/.local/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=1,\n",
       "  decision_function_shape='ovr', degree=2, gamma='auto_deprecated',\n",
       "  kernel='poly', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Poly Kernel!\")\n",
    "\n",
    "mySvm_5P = svm.SVC(kernel='poly', degree=2, coef0=1)\n",
    "mySvm_5P.fit(_5_trainSet_X, _5_trainSet_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error is :  2.100000000000002 %\n",
      "Training Error is :  0.0 %\n",
      "Number of support vectors:  1755\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "pred = mySvm_5P.predict(_5_validSet_X)\n",
    "pred_train = mySvm_5P.predict(_5_trainSet_X)\n",
    "print(\"Test Error is : \", (1-accuracy_score(_5_validSet_y, pred))*100, \"%\")\n",
    "print(\"Training Error is : \", (1-accuracy_score(_5_trainSet_y, pred_train))*100, \"%\")\n",
    "print(\"Number of support vectors: \", mySvm_5P.n_support_.sum())\n",
    "print(\"---------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Both yield equal training error of 0%. However, on test data, rbf kernel performs very poorly ~50% accuracy, whereas polynomial kernel gives high ~98% accuracy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a)\n",
    "\n",
    "Here:\n",
    "\n",
    "* I have used the random subset of data to be chosen for training each tree to be 4/5th of total training set.\n",
    "\n",
    "* k = number of trees = 10\n",
    "\n",
    "* To prevent infinite recursion (there is some probability that the random attributes are such that they do not result in a split, but still contain objects of different classes), recursion has been stopped in such cases.\n",
    "\n",
    "* Decision tree class from previous assignment has been modified slightly to suit my needs\n",
    "\n",
    "* A new **class** for random forests, **MyRF()** has been created. Its parameters are self explanatory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data !\n",
    "import numpy as np\n",
    "f = open(\"spam.data\", \"r\")\n",
    "rawSet_6 = np.loadtxt(f)\n",
    "\n",
    "np.random.shuffle(rawSet_6)\n",
    "#print(rawSet_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30 % data is test data!\n",
    "test_set_6 = [x for i, x in enumerate(rawSet_6) if i % 10 == 9 or i % 10 == 6 or i%7 == 3]\n",
    "train_set_6 =  [x for i, x in enumerate(rawSet_6) if i % 10 != 9 and i % 10 != 6 and i%7 != 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not used as such, but should do it so that python list-comprehends train_set_6 and \n",
    "# does not cause recursion error\n",
    "train_set_6_X = [x[:-1] for x in (train_set_6) ]\n",
    "train_set_6_y = [x[-1] for x in (train_set_6)]\n",
    "\n",
    "test_set_6_X = [x[:-1] for x in (test_set_6) ]\n",
    "test_set_6_y = [x[-1] for x in (test_set_6)]\n",
    "#print(train_set_6_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# Total number of attribs\n",
    "M = 58\n",
    "# Number of features for split! , Last is class label.\n",
    "m2 = (math.sqrt(M-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     10,
     112,
     117
    ]
   },
   "outputs": [],
   "source": [
    "# Decision Tree code.\n",
    "#print(train_set_6)\n",
    "#print(test_set_6)\n",
    "## Code for decision Tree!\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "# Enter You Name Here\n",
    "myname = \"Supreet\" # or \"Doe-Jane-\"\n",
    "\n",
    "class Node():\n",
    "    left = None\n",
    "    right = None\n",
    "    ans = 2 # 2 means none, 0,1 -> the classification\n",
    "    attrib = 0 #index of attribute to split on\n",
    "    val = 0 #the value to split on. \n",
    "    def __init__(self, a, v, q):\n",
    "        self.attrib = a\n",
    "        self.val = v\n",
    "        self.ans = q\n",
    "        \n",
    "    def isLeaf(self): #boolean\n",
    "        if self.ans == 2:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "\n",
    "# Implement your decision tree below\n",
    "class DecisionTree():\n",
    "    tree = Node(0, 0, 2)\n",
    "    \n",
    "    \n",
    "    m_feat = -1 #Need to be set manually to >0\n",
    "    #train_set = []\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.train_data = []\n",
    "    \n",
    "    def splitVal(self, data, idx): # retuurns mean\n",
    "        sum = 0.0\n",
    "        for x in data:\n",
    "            sum = sum+ float(x[idx])\n",
    "        \n",
    "        return float(float(sum)/float(len(data)))\n",
    "        \n",
    "    def entropy(self, pa, na, ntot): #returns float.\n",
    "        if pa == 1 or pa == 0:\n",
    "            return 0\n",
    "        #print(pa)\n",
    "        \n",
    "        e = float(pa) * float(math.log(pa, 2))\n",
    "        e = e + float((1-pa) * math.log(1-pa, 2))\n",
    "        \n",
    "        return float(-1)*(float(na)/float(ntot))*e\n",
    "        \n",
    "    \n",
    "    def prob1(self, data): #Probability of items to be in class 1.\n",
    "        if len(data) == 0:\n",
    "            return float(0)\n",
    "        \n",
    "        sum = 0\n",
    "        for x in data:\n",
    "            sum = sum + int(x[M-1]) # 11th index (12th elem) is the quality\n",
    "        #print(\"sum: \", sum, \"len: \", len(data))\n",
    "        g= float(float(sum)/float(len(data)))\n",
    "        #print(\"prob:\", g)\n",
    "        return g\n",
    "    \n",
    "    def learn(self, training_set): #returns a node with the split conditions.\n",
    "        # implement this function\n",
    "         \n",
    "        if len(training_set) == 0:\n",
    "            return None\n",
    "        \n",
    "        tpl = self.splitNode(training_set)\n",
    "        root = Node(tpl[1], tpl[2], 2)\n",
    "        \n",
    "        #print(\"got tuple to split: @ attrib: %d, value: %f\" % (root.attrib, root.val) )\n",
    "        \n",
    "        if self.prob1(training_set) == 1 :\n",
    "            root.ans = 1\n",
    "            return root\n",
    "        \n",
    "        elif self.prob1(training_set) == 0:\n",
    "            root.ans = 0\n",
    "            return root\n",
    "        \n",
    "        else :\n",
    "            #self.depth = self.depth + 1\n",
    "            #print(self.depth)\n",
    "            l1 = [x for x in training_set if float(x[root.attrib]) <= root.val]\n",
    "            l2 = [x for x in training_set if float(x[root.attrib]) > root.val]\n",
    "            \n",
    "            #print(\"left: %d, right %d\" %(len(l1), len(l2)))\n",
    "            if np.array_equal(training_set, l1):\n",
    "                root.ans = 1 if self.prob1(l1) > 0.5 else 0\n",
    "                return root\n",
    "            elif np.array_equal(training_set, l2):\n",
    "                root.ans = 1 if self.prob1(l2) > 0.5 else 0\n",
    "                return root\n",
    "            \n",
    "            root.left = self.learn(l1)\n",
    "            root.right = self.learn(l2)\n",
    "            return root\n",
    "        '''else:\n",
    "            if self.prob1(training_set)>0.5:\n",
    "                root.ans = 1\n",
    "                return root\n",
    "            else:\n",
    "                root.ans = 0\n",
    "                return root\n",
    "        '''\n",
    "\n",
    "    # implement this function\n",
    "    def classify(self, test_instance):\n",
    "        #result = 0 # baseline: always classifies as 0\n",
    "        result = self.treeTraverse(test_instance, self.tree)\n",
    "        return result\n",
    "    \n",
    "    def treeTraverse(self, x_vector, node: Node) -> int:\n",
    "        if node is None:\n",
    "            return -1\n",
    "        elif not node.isLeaf():\n",
    "            return node.ans\n",
    "        elif float(x_vector[node.attrib]) <= node.val:\n",
    "            return self.treeTraverse(x_vector, node.left)\n",
    "        else:\n",
    "            return self.treeTraverse(x_vector, node.right)\n",
    "            \n",
    "        \n",
    "    \n",
    "    def splitNode(self, data): # returns the minimum entropy.\n",
    "        me = float(11000)\n",
    "        index = 0\n",
    "        Nm = len(data)\n",
    "        mSVal = 0.0\n",
    "        \n",
    "        # Choose a random list of features to check split on!\n",
    "        split_features = []\n",
    "        #print(self.m_feat)\n",
    "        \n",
    "        split_features = np.random.choice(np.arange(M-1), int(self.m_feat), replace=False)\n",
    "        #print(split_features)\n",
    "        for i in split_features: # 11 is the number of attributes \n",
    "            sv = self.splitVal(data, i)\n",
    "            l1 = [x for x in data if float(x[i]) <= sv]\n",
    "            l2 = [x for x in data if float(x[i]) > sv]\n",
    "            pa1 = self.prob1(l1)\n",
    "            pa2 = self.prob1(l2)\n",
    "            #print(\"## \", pa1, pa2)\n",
    "            eThis = self.entropy(pa1, len(l1), Nm) + self.entropy(pa2, len(l2), Nm)\n",
    "            #print(\"Entropy got: %f, me was: \" % eThis, me)\n",
    "            #print(eThis < me)\n",
    "                \n",
    "            if eThis < me:\n",
    "                me = eThis\n",
    "                index = i\n",
    "                mSVal = sv\n",
    "            '''\n",
    "            me = eThis if eThis < me else me\n",
    "            index = i if eThis < me else index\n",
    "            print(\"inedx now is: %d\" % index)\n",
    "            mSVal = sv if eThis < me else mSVal\n",
    "            '''\n",
    "            #min = eThis < min ? eThis : min\n",
    "        return (me, index, mSVal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class MyRF():\n",
    "    #k = 10 # Number of trees.\n",
    "    #subSize = 20 # Size of subset of training points!\n",
    "    #trees = []\n",
    "    #m \n",
    "    def __init__(self, k, subSize, features_to_split):\n",
    "        self.k = k\n",
    "        self.subSize = int(subSize)\n",
    "        self.m = int(features_to_split)\n",
    "        self.trees=[]\n",
    "        self.oobError = 0.0\n",
    "    \n",
    "    def learnForest(self, data):\n",
    "        for i in range(self.k):\n",
    "            tree = DecisionTree()\n",
    "            tree.m_feat = int(self.m)\n",
    "            #print(type(data[:self.subSize]))\n",
    "            #tree.tree = tree.learn(random.choices(data, k=self.subSize))\n",
    "            #np.random.shuffle(data)\n",
    "            dt = random.choices(data, k=self.subSize)\n",
    "            tree.tree = tree.learn(dt)\n",
    "            tree.train_data = (np.unique(dt))\n",
    "            self.trees.append(tree)\n",
    "            \n",
    "    \n",
    "    def classify(self, dataPoint): # data point is without the class label!\n",
    "        n1 = 0\n",
    "        \n",
    "        for i in range(self.k):\n",
    "            result = self.trees[i].classify(dataPoint)\n",
    "            n1 = n1 + result\n",
    "        \n",
    "        if n1 >= int(self.k/2): # Majority Voting!!\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def OOBClassify(self, dataPoint):\n",
    "        n1 = 0\n",
    "        tc = 0\n",
    "        for i in range(self.k):\n",
    "            ans = self.OOBIn(dataPoint, self.trees[i].train_data)\n",
    "            if ans==True:\n",
    "                result = self.trees[i].classify(dataPoint)\n",
    "                n1 = n1 + result\n",
    "                tc+=1\n",
    "        \n",
    "        if n1 >= int(tc/2): # Majority Voting!!\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    \n",
    "    def OOBIn(self, dataPoint, dataSet):\n",
    "        if dataPoint in dataSet:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def getOOBError(self, data):\n",
    "        self.oobError = 0\n",
    "        results = []\n",
    "        \n",
    "        for instance in data:\n",
    "            result = self.OOBClassify( instance[:-1] )\n",
    "            results.append( (result) == int(instance[-1]))\n",
    "        \n",
    "        self.oobError += float(results.count(False)/float(len(results)))\n",
    "        return float(self.oobError/self.k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = MyRF(10, subSize=len(train_set_6)/1.25, features_to_split=int(m2))\n",
    "rf.learnForest(train_set_6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9475\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for instance in test_set_6:\n",
    "    result = rf.classify( instance[:-1] )\n",
    "    results.append( (result) == int(instance[-1]))\n",
    "    \n",
    "accuracy = float(results.count(True))/float(len(results))\n",
    "print (\"accuracy: %.4f\" % accuracy) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing with sklearn's random forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9426399447131997\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "clf.fit(train_set_6_X, train_set_6_y)\n",
    "\n",
    "pred = clf.predict(test_set_6_X)\n",
    "\n",
    "print(\"accuracy: \", accuracy_score(test_set_6_y, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My implementation gave slighly **higher** (ON AVERAGE) accuracy compared to sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b)\n",
    "\n",
    "Sensitivity to 'm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/supreet/.local/lib/python3.6/site-packages/ipykernel_launcher.py:55: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For m =  1.8874586088176875 -> Accuracy = 0.8832\n",
      "OOB Error =  0.010716550412175016\n",
      "-------------------------\n",
      "Iteration:  1\n",
      "For m =  2.516611478423583 -> Accuracy = 0.9267\n",
      "OOB Error =  0.004946100190234623\n",
      "-------------------------\n",
      "Iteration:  2\n",
      "For m =  3.774917217635375 -> Accuracy = 0.9357\n",
      "OOB Error =  0.003233988585922638\n",
      "-------------------------\n",
      "Iteration:  3\n",
      "For m =  7.54983443527075 -> Accuracy = 0.9454\n",
      "OOB Error =  0.0015535827520608751\n",
      "-------------------------\n",
      "Iteration:  4\n",
      "For m =  15.0996688705415 -> Accuracy = 0.9461\n",
      "OOB Error =  0.0006975269499048827\n",
      "-------------------------\n",
      "Iteration:  5\n",
      "For m =  22.64950330581225 -> Accuracy = 0.9496\n",
      "OOB Error =  0.0007926442612555485\n",
      "-------------------------\n",
      "Iteration:  6\n",
      "For m =  30.199337741083 -> Accuracy = 0.9447\n",
      "OOB Error =  0.0008560558021559923\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "m_vals = [m2/4,m2/3, m2/2, m2, 2*m2, 3*m2, 4*m2]\n",
    "\n",
    "acc_s = []\n",
    "oobE = []\n",
    "\n",
    "i=0\n",
    "\n",
    "for md in m_vals:\n",
    "    rf =  MyRF(10, subSize=len(train_set_6)/1.25, features_to_split=int(md))\n",
    "    rf.learnForest(train_set_6)\n",
    "    results2 = []\n",
    "    acc = []\n",
    "    for instance2 in test_set_6:\n",
    "        result = rf.classify( instance2[:-1] )\n",
    "        #print(\"ithpoint: \", i, \"as: \", result)\n",
    "        #i+=1\n",
    "        results2.append( (result) == int(instance2[-1]))\n",
    "    #print((results.count(True)))\n",
    "    print(\"Iteration: \", i)\n",
    "    accuracy2 = float(results2.count(True))/float(len(results2))\n",
    "    acc_s.append(accuracy2)\n",
    "    oobE.append(rf.getOOBError(train_set_6))\n",
    "    print (\"For m = \", md,\"-> Accuracy = %.4f\" % accuracy2)\n",
    "    print(\"OOB Error = \", oobE[i])\n",
    "    print(\"-------------------------\")\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, ** m2 ** = sqrt(Number of Attributes)\n",
    " \n",
    "Value of m has been chosen from this range: [m2/4,m2/3, m2/2, m2, 2 x m2, 3 x m2, 4 x m2]\n",
    "\n",
    "**Observations**\n",
    "\n",
    "For lower values of 'm', the classifier is very sensitive to changes in the value of m, with accuracy changing dramatically for small changes in m. However, at larger values ~ $ 2 * m2 $, this sensitivity reduces and accuracy changes only slightly for changes in m."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(m_vals, oobE)\n",
    "plt.xlabel(\"m: Number of features\")\n",
    "plt.ylabel(\"OOB Error\")\n",
    "plt.title(\"m vs OOB Error\")\n",
    "plt.show()\n",
    "\n",
    "print(\"---------------------------------\")\n",
    "\n",
    "plt.plot(m_vals, [1-x for x in acc_s])\n",
    "plt.xlabel(\"m: Number of features\")\n",
    "plt.ylabel(\"Test Error\")\n",
    "plt.title(\"m vs Testing Error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "\n",
    "* OOB Error decreases rapidly for small values of m\n",
    "* OOB Error almost stabilizes for larger values of m (> $ \\sqrt{Number of Features} $ )\n",
    "* Similarly for testing error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
